dat = read.csv(file.path(v_path, "final_v1.csv"), header=T,
na.strings=c("", " ", "NA"))
str(dat)
# source main plot to make the plots
source(file.path(proj_path, "plot-main.R"))
# rmasterve all R objects in the working directory
rm(list=ls())
library(dplyr)
library(tidyr)
library(ggplot2)
# set path
proj_path = "~/Projects/54_steve_t/2015/clr015002"
out_path = file.path(proj_path, "output")
v_path = file.path(out_path, "v1")
plt_path = file.path(v_path, "plot")
dir.create(plt_path, showWarnings = F)
helper_path = file.path(proj_path, "helper")
# source helper file
source(file.path(helper_path, "plt-helper.R"))
source(file.path(helper_path, "multiplot.R"))
source(file.path(helper_path, "plt-event-cnt.R"))
source(file.path(helper_path, "plt-event-cnt2.R"))
source(file.path(helper_path, "plt-avg-intensity.R"))
source(file.path(helper_path, "plt-avg-intensity2.R"))
# read data
options(stringsAsFactors=FALSE)
dat = read.csv(file.path(v_path, "final_v1.csv"), header=T,
na.strings=c("", " ", "NA"))
str(dat)
# source main plot to make the plots
source(file.path(proj_path, "plot-main.R"))
# rmasterve all R objects in the working directory
rm(list=ls())
library(dplyr)
library(tidyr)
library(ggplot2)
# set path
proj_path = "~/Projects/54_steve_t/2015/clr015002"
out_path = file.path(proj_path, "output")
v_path = file.path(out_path, "v1")
plt_path = file.path(v_path, "plot")
dir.create(plt_path, showWarnings = F)
helper_path = file.path(proj_path, "helper")
# source helper file
source(file.path(helper_path, "plt-helper.R"))
source(file.path(helper_path, "multiplot.R"))
source(file.path(helper_path, "plt-event-cnt.R"))
source(file.path(helper_path, "plt-event-cnt2.R"))
source(file.path(helper_path, "plt-avg-intensity.R"))
source(file.path(helper_path, "plt-avg-intensity2.R"))
# read data
options(stringsAsFactors=FALSE)
dat = read.csv(file.path(v_path, "final_v1.csv"), header=T,
na.strings=c("", " ", "NA"))
str(dat)
# source main plot to make the plots
source(file.path(proj_path, "plot-main.R"))
# rmasterve all R objects in the working directory
rm(list=ls())
library(dplyr)
library(tidyr)
library(ggplot2)
# set path
proj_path = "~/Projects/54_steve_t/2015/clr015002"
out_path = file.path(proj_path, "output")
v_path = file.path(out_path, "v1")
plt_path = file.path(v_path, "plot")
dir.create(plt_path, showWarnings = F)
helper_path = file.path(proj_path, "helper")
# source helper file
source(file.path(helper_path, "plt-helper.R"))
source(file.path(helper_path, "multiplot.R"))
source(file.path(helper_path, "plt-event-cnt.R"))
source(file.path(helper_path, "plt-event-cnt2.R"))
source(file.path(helper_path, "plt-avg-intensity.R"))
source(file.path(helper_path, "plt-avg-intensity2.R"))
# read data
options(stringsAsFactors=FALSE)
dat = read.csv(file.path(v_path, "final_v1.csv"), header=T,
na.strings=c("", " ", "NA"))
str(dat)
# source main plot to make the plots
source(file.path(proj_path, "plot-main.R"))
# rmasterve all R objects in the working directory
rm(list=ls())
library(dplyr)
library(tidyr)
library(ggplot2)
# set path
proj_path = "~/Projects/54_steve_t/2015/clr015002"
out_path = file.path(proj_path, "output")
v_path = file.path(out_path, "v2")
plt_path = file.path(v_path, "plot")
dir.create(plt_path, showWarnings = F)
helper_path = file.path(proj_path, "helper")
# source helper file
source(file.path(helper_path, "plt-helper.R"))
source(file.path(helper_path, "multiplot.R"))
source(file.path(helper_path, "plt-event-cnt.R"))
source(file.path(helper_path, "plt-event-cnt2.R"))
source(file.path(helper_path, "plt-avg-intensity.R"))
source(file.path(helper_path, "plt-avg-intensity2.R"))
# read data
options(stringsAsFactors=FALSE)
dat = read.csv(file.path(v_path, "final_v2.csv"), header=T,
na.strings=c("", " ", "NA"))
str(dat)
# source main plot to make the plots
source(file.path(proj_path, "plot-main.R"))
# rmasterve all R objects in the working directory
rm(list=ls())
library(dplyr)
library(tidyr)
library(ggplot2)
# set path
proj_path = "~/Projects/54_steve_t/2015/clr015002"
out_path = file.path(proj_path, "output")
v_path = file.path(out_path, "v2")
plt_path = file.path(v_path, "plot")
dir.create(plt_path, showWarnings = F)
helper_path = file.path(proj_path, "helper")
# source helper file
source(file.path(helper_path, "plt-helper.R"))
source(file.path(helper_path, "multiplot.R"))
source(file.path(helper_path, "plt-event-cnt.R"))
source(file.path(helper_path, "plt-event-cnt2.R"))
source(file.path(helper_path, "plt-avg-intensity.R"))
source(file.path(helper_path, "plt-avg-intensity2.R"))
# read data
options(stringsAsFactors=FALSE)
dat = read.csv(file.path(v_path, "final_v2.csv"), header=T,
na.strings=c("", " ", "NA"))
str(dat)
# source main plot to make the plots
source(file.path(proj_path, "plot-main2.R"))
# rm all R objects in the working directory
rm(list=ls())
library(dplyr)
library(tidyr)
library(ggplot2)
# set path
proj_path = "~/Projects/54_steve_t/2015/clr015002"
helper_path = file.path(proj_path, "helper")
out_path = file.path(proj_path, "output")
v1_path = file.path(out_path, "v1")
v2_path = file.path(out_path, "v2")
compare_path = file.path(out_path, "compare")
plt_path = file.path(compare_path, "plot")
dir.create(compare_path, showWarnings = F)
dir.create(plt_path, showWarnings = F)
# source helper file
source(file.path(helper_path, "plt-helper.R"))
source(file.path(helper_path, "plt-compare-visits-cnt.R"))
source(file.path(helper_path, "plt-compare-visits-intensity.R"))
# read data
options(stringsAsFactors=FALSE)
v1 = read.csv(file.path(v1_path, "final_v1.csv"), header=T,
na.strings=c("", " ", "NA"))
v2 = read.csv(file.path(v2_path, "final_v2.csv"), header=T,
na.strings=c("", " ", "NA"))
# collect visits data into a list
lst = list(v1, v2)
names(lst) = c("v1", "v2")
### count of events by study arm (Not Broken Down by Emotion) ######
# plot
p = plt_compare_visits_cnt(lst, "study_arm")
# save plot
plt_name = "Compare Visits - Incidence of Emotional Engagement by Study Arm (Not Broken Down by Emotion)"
ggsave(plot=p, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
### count of events by event relationship to exposure (Not Broken Down by Emotion) ######
# plot
p = plt_compare_visits_cnt(lst, "event_relationship")
# save plot
plt_name = "Compare Visits - Incidence of Emotional Engagement by Event Relationship (Not Broken Down by Emotion)"
ggsave(plot=p, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
### count of events by area of contact (Not Broken Down by Emotion) ######
# plot
p = plt_compare_visits_cnt(lst, "area_of_contact")
# save plot
plt_name = "Compare Visits - Incidence of Emotional Engagement by Area of Contact (Not Broken Down by Emotion)"
ggsave(plot=p, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
### count of events by product size (Not Broken Down by Emotion) ######
# plot
p = plt_compare_visits_cnt(lst, "product_size")
# save plot
plt_name = "Compare Visits - Incidence of Emotional Engagement by Product Size (Not Broken Down by Emotion)"
ggsave(plot=p, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
### count of events by treatment (Not Broken Down by Emotion) ######
# plot
p = plt_compare_visits_cnt(lst, "treatment")
# save plot
plt_name = "Compare Visits - Incidence of Emotional Engagement by Application Method (Not Broken Down by Emotion)"
ggsave(plot=p, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
## avg intensity & pct of emotions by study arm (Not Broken Down by Emotion) ###
# plot
ggplts = plt_compare_visits_intensity(lst, "study_arm", barlab_at_top=T)
gg_avg = ggplts[["plts_avg"]]
gg_pct = ggplts[["plts_pct"]]
# save plot
plt_name = "Compare Visits - Emotional Engagement by Study Arm (Not Broken Down by Emotion)"
ggsave(plot=gg_avg, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
plt_name = "Compare Visits - Percent of Emotions by Study Arm (Not Broken Down by Emotion)"
ggsave(plot=gg_pct, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
## avg intensity & pct of emotions by event relationship (Not Broken Down by Emotion) ###
# plot
ggplts = plt_compare_visits_intensity(lst, "event_relationship", barlab_at_top=T)
gg_avg = ggplts[["plts_avg"]]
gg_pct = ggplts[["plts_pct"]]
# save plot
plt_name = "Compare Visits - Emotional Engagement by Event Relationship (Not Broken Down By Emotion)"
ggsave(plot=gg_avg, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
plt_name = "Compare Visits - Percent of Emotions by Event Relationship (Not Broken Down By Emotion)"
ggsave(plot=gg_pct, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
## avg intensity & pct of emotions by area of contact (Not Broken Down By Emotion) ##
# plot
ggplts = plt_compare_visits_intensity(lst, "area_of_contact", barlab_at_top=T)
gg_avg = ggplts[["plts_avg"]]
gg_pct = ggplts[["plts_pct"]]
# save plot (ignore "None (for image)")
plt_name = "Compare Visits - Emotional Engagement by Area of Contact (Not Broken Down By Emotion)"
ggsave(plot=gg_avg, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
plt_name = "Compare Visits - Percent of Emotions by Area of Contact (Not Broken Down By Emotion)"
ggsave(plot=gg_pct, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
## avg intensity & pct of emotions by product size (Not Broken Down By Emotion) ##
# plot
ggplts = plt_compare_visits_intensity(lst, "product_size", barlab_at_top=T)
gg_avg = ggplts[["plts_avg"]]
gg_pct = ggplts[["plts_pct"]]
# save plot
plt_name = "Compare Visits - Emotional Engagement by Product Size (Not Broken Down By Emotion)"
ggsave(plot=gg_avg, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
plt_name = "Compare Visits - Percent of Emotions by Product Size (Not Broken Down By Emotion)"
ggsave(plot=gg_pct, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
## avg intensity & pct of emotions by Application Method (Not Broken Down by Emotion) ###
# plot
ggplts = plt_compare_visits_intensity(lst, "treatment", barlab_at_top=T)
gg_avg = ggplts[["plts_avg"]]
gg_pct = ggplts[["plts_pct"]]
# save plot
plt_name = "Compare Visits - Emotional Engagement by Application Method (Not Broken Down By Emotion)"
ggsave(plot=gg_avg, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
plt_name = "Compare Visits - Percent of Emotions by Application Method (Not Broken Down By Emotion)"
ggsave(plot=gg_pct, filename=file.path(plt_path, paste(plt_name, "png", sep=".")))
proj_path = "~/score-loan-applicants"
data_path = file.path(proj_path, 'data')
file_path = file.path(data_path, 'cleaned-06.rda')
load(file_path)
set.seed(123294)
train = sample(1:nrow(upl), round(nrow(upl)*0.6))
dat_train = upl[train, ]
dat_test = upl[-train, ]
print(predictors)
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "03-01-model-selection-using-bestsubsets.Rmd")
knitr::knit(file_in)
install.packages("glmulti")
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "03-01-model-selection-using-bestsubsets.Rmd")
knitr::knit(file_in)
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "03-01-model-selection-using-bestsubsets.Rmd")
knitr::knit(file_in)
proj_path = "~/score-loan-applicants"
data_path = file.path(proj_path, 'data')
file_path = file.path(data_path, 'cleaned-01.rda')
load(file_path)
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "02-02-descriptive-analysis.Rmd")
knitr::knit(file_in)
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "02-02-descriptive-analysis.Rmd")
knitr::knit(file_in)
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "02-03-WoE-n-IV.Rmd")
knitr::knit(file_in)
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "02-04-simple-logit.Rmd")
knitr::knit(file_in)
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "02-05-preselect-predictors.Rmd")
knitr::knit(file_in)
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "02-06-correlations.Rmd")
knitr::knit(file_in)
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "03-01-model-selection-using-bestsubsets.Rmd")
knitr::knit(file_in)
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "03-01-model-selection-using-bestsubsets.Rmd")
knitr::knit(file_in)
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "02-06-correlations.Rmd")
knitr::knit(file_in)
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "02-06-correlations.Rmd")
knitr::knit(file_in)
bestfit = glm(fbest, data=dat_train, family=binomial)
proj_path = "~/score-loan-applicants"
data_path = file.path(proj_path, 'data')
file_path = file.path(data_path, 'cleaned-06.rda')
load(file_path)
# split dat into training (60%) and testing (40%) sets
set.seed(123294)
train = sample(1:nrow(upl), round(nrow(upl)*0.6))
dat_train = upl[train, ]
dat_test = upl[-train, ]
library(glmulti)
t0 = proc.time() # record starting time
f = as.formula(paste0("bad ~ ", paste(predictors, collapse=" + ")))
bestsub_logit = glmulti(f, data = dat_train,
level = 1, # no interaction considered
method = "h", # exhaustive approach
crit = "aic", # AIC as criteria
confsetsize = 5, # keep 5 best models
plotty = F, report = F, # no plot or interim reports
fitfunction = "glm", # glm function
family = binomial) # binomial family for logit model
cat("Run time: ")
print(proc.time() - t0) # calculating time it took to run the models
summary(bestsub_logit@objects[[1]])
temp = as.character(bestsub_logit@formulas[[1]])[3]
main_effects = strsplit(temp, " \\+ ")[[1]][-1]
print(main_effects)
interact_terms1 = c("marital:bankruptcy",
"bankruptcy:market_value_cat")
interact_terms2 = c("credit_line_age:bankruptcy",
"credit_line_age:market_value_cat",
"log_annual_income:bankruptcy",
"log_annual_income:market_value_cat")
interactions = c(interact_terms1, interact_terms2)
base_model = paste0("bad ~ ", paste(main_effects, collapse=" + "))
# create list of models
list_of_models = lapply(seq_along(interactions), function(n) {
left = base_model
right = apply(combn(interactions, n), 2, paste, collapse = " + ")
paste(left, right, sep = " + ")
})
# convert to vector
vec_of_models = unlist(list_of_models)
vec_of_models = c(base_model, vec_of_models)
list_of_fits = lapply(vec_of_models, function(x) {
formula = as.formula(x)
fit = glm(formula, data=dat_train, family=binomial)
result_AIC = extractAIC(fit)
data.frame(predictor_cnt = result_AIC[1],
AIC = result_AIC[2], model = x, stringsAsFactors=F)
})
result = do.call(rbind, list_of_fits) # collapse to a data frame
result = result[order(result$AIC),] # sort
fbest = as.formula(result$model[1])
fbest
bestfit = glm(fbest, data=dat_train, family=binomial)
bestfit
coef(bestfit)
rm(list=ls())
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "03-01-model-selection-using-bestsubsets.Rmd")
knitr::knit(file_in)
proj_path = "~/score-loan-applicants"
data_path = file.path(proj_path, 'data')
file_path = file.path(data_path, 'cleaned-06.rda')
load(file_path)
# split dat into training (60%) and testing (40%) sets
set.seed(123294)
train = sample(1:nrow(upl), round(nrow(upl)*0.6))
dat_train = upl[train, ]
dat_test = upl[-train, ]
library(glmulti)
t0 = proc.time() # record starting time
f = as.formula(paste0("bad ~ ", paste(predictors, collapse=" + ")))
bestsub_logit = glmulti(f, data = dat_train,
level = 1, # no interaction considered
method = "h", # exhaustive approach
crit = "aic", # AIC as criteria
confsetsize = 5, # keep 5 best models
plotty = F, report = F, # no plot or interim reports
fitfunction = "glm", # glm function
family = binomial) # binomial family for logit model
cat("Run time: ")
print(proc.time() - t0) # calculating time it took to run the models
temp = as.character(bestsub_logit@formulas[[1]])[3]
main_effects = strsplit(temp, " \\+ ")[[1]][-1]
interact_terms1 = c("marital:bankruptcy",
"bankruptcy:market_value_cat")
interact_terms2 = c("credit_line_age:bankruptcy",
"credit_line_age:market_value_cat",
"log_annual_income:bankruptcy",
"log_annual_income:market_value_cat")
interactions = c(interact_terms1, interact_terms2)
base_model = paste0("bad ~ ", paste(main_effects, collapse=" + "))
# create list of models
list_of_models = lapply(seq_along(interactions), function(n) {
left = base_model
right = apply(combn(interactions, n), 2, paste, collapse = " + ")
paste(left, right, sep = " + ")
})
# convert to vector
vec_of_models = unlist(list_of_models)
vec_of_models = c(base_model, vec_of_models)
list_of_fits = lapply(vec_of_models, function(x) {
formula = as.formula(x)
fit = glm(formula, data=dat_train, family=binomial)
result_AIC = extractAIC(fit)
data.frame(predictor_cnt = result_AIC[1],
AIC = result_AIC[2], model = x, stringsAsFactors=F)
})
result = do.call(rbind, list_of_fits) # collapse to a data frame
result = result[order(result$AIC),] # sort
fbest = as.formula(result$model[1])
fbest
bestfit = glm(fbest, data=dat_train, family=binomial)
round(coef(bestfit), 3)
150 / 1.1
150 / 0.9
166.67 * 0.9
install.packages("readr")
install.packages("readxl")
install.packages("haven")
install.packages("DBI")
install.packages("curl")
install.packages("httr")
install.packages("xml2")
install.packages("jsonlite")
install.packages("rvest")
devtools::install_github("RcppCore/Rcpp")
devtools::install_github("rstats-db/DBI")
devtools::install_github("rstats-db/RMySQL")
devtools::install_github("rstats-db/RSQLite")
devtools::install_github("rstats-db/RPostgres")
