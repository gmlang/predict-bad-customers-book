reduced_rate = round(contribution_rate / (1+contribution_rate), 3)
reduced_rate
contribution_rate = 1/100
reduced_rate = round(contribution_rate / (1+contribution_rate), 3)
reduced_rate
reduced_rate = contribution_rate / (1+contribution_rate)
reduced_rate
contribution_rate = 2/100
reduced_rate = contribution_rate / (1+contribution_rate)
reduced_rate
## calculate annual max contribution for solo 401k
rm(list=ls())
# constant
elective_deferral_cap = 18000 # 2015
contribution_rate_cap = 0.25 # can contribute > 25%, however, can only deduct 25% max.
# user input
income = 50000
expense = 10000 # non-salary biz expense
elective_deferral = elective_deferral_cap
contribution_rate = contribution_rate_cap
reduced_rate = contribution_rate / (1+contribution_rate)
# set paths
proj_path = "~/Dropbox/me/tax-calculator"
source(file.path(proj_path, "calc-tax-sole.R"))
lst_sole = calc_tax_sole(proj_path, income, expense)
lst_sole[[1]]
net_profit = income - expense
se_tax = lst_sole[[1]]$se_tax
se_net_earnings = net_profit - 0.5 * se_tax
contribution = se_net_earnings * reduced_rate
contribution
contribution2 = compensation_cap * contribution_rate_cap
## calculate annual max contribution for solo 401k
rm(list=ls())
# for the year 2015
elective_deferral_cap = 18000
compensation_cap = 265000
contribution_max_deduct_rate = 0.25
contribution_dollar_limit = 53000
# user input
income = 50000
expense = 10000 # non-salary biz expense
elective_deferral = elective_deferral_cap
contribution_rate = contribution_max_deduct_rate
reduced_rate = contribution_rate / (1+contribution_rate)
proj_path = "~/Dropbox/me/tax-calculator"
source(file.path(proj_path, "calc-tax-sole.R"))
lst_sole = calc_tax_sole(proj_path, income, expense)
lst_sole[[1]]
net_profit = income - expense
se_tax = lst_sole[[1]]$se_tax
se_net_earnings = net_profit - 0.5 * se_tax
contribution1 = se_net_earnings * reduced_rate
contribution2 = compensation_cap * contribution_rate
contribution = min(contribution1, contribution2)
contribution
income = 40000
expense = 10000 # non-salary biz expense
elective_deferral = elective_deferral_cap
contribution_rate = contribution_max_deduct_rate
reduced_rate = contribution_rate / (1+contribution_rate)
# set paths
proj_path = "~/Dropbox/me/tax-calculator"
source(file.path(proj_path, "calc-tax-sole.R"))
lst_sole = calc_tax_sole(proj_path, income, expense)
lst_sole[[1]]
net_profit = income - expense
se_tax = lst_sole[[1]]$se_tax
se_net_earnings = net_profit - 0.5 * se_tax
contribution1 = se_net_earnings * reduced_rate
contribution2 = compensation_cap * contribution_rate
contribution = min(contribution1, contribution2)
contribution
step13 = min(1,2,3)
min(1,2,3)
## calculate annual max contribution for solo 401k
rm(list=ls())
# for the year 2015
elective_deferral_cap = 18000
compensation_cap = 265000
contribution_max_deduct_rate = 0.25
contribution_dollar_limit = 53000 # step8
# user input
income = 40000
expense = 10000 # non-salary biz expense
elective_deferral = elective_deferral_cap # step9
contribution_rate = contribution_max_deduct_rate
reduced_rate = contribution_rate / (1+contribution_rate) # step4
# set paths
proj_path = "~/Dropbox/me/tax-calculator"
source(file.path(proj_path, "calc-tax-sole.R"))
lst_sole = calc_tax_sole(proj_path, income, expense)
lst_sole[[1]]
net_profit = income - expense # step1
se_tax = lst_sole[[1]]$se_tax # step2
se_net_earnings = net_profit - 0.5 * se_tax # step3
contribution1 = se_net_earnings * reduced_rate # step5
contribution2 = compensation_cap * contribution_rate # step6
contribution = min(contribution1, contribution2) # step7
step10 = contribution_dollar_limit - elective_deferral
step11 = se_net_earnings - elective_deferral
step12 = 0.5 * step11
step13 = min(contribution, step10, step12)
step14 = se_net_earnings - step13
step15 = min(elective_deferral, step14)
# no catch-up contribution
step19 = step13 + step15
step20 = 0 # no designated Roth contributions
# finally
max_deductible_contribution = step19 - step20
max_deductible_contribution
contribution + 18000
rm(list=ls())
income = 50000
expense = 10000 # non-salary biz expense
proj_path = "~/Dropbox/me/tax-calculator"
source(file.path(proj_path, "calc-tax-scorp.R"))
source(file.path(proj_path, "calc-tax-sole.R"))
rm(list=ls())
# user input
income = 50000
expense = 10000 # non-salary biz expense
# set paths
proj_path = "~/Dropbox/me/tax-calculator"
source(file.path(proj_path, "calc-tax-sole.R"))
lst_sole = calc_tax_sole(proj_path, income, expense)
lst_sole[[1]]
source(file.path(proj_path, "calc-tax-scorp.R"))
lst_scorp = calc_tax_scorp(proj_path, income, expense, salary_pct)
rm(list=ls())
# user input
income = 50000
expense = 10000 # non-salary biz expense
# set paths
proj_path = "~/Dropbox/me/tax-calculator"
source(file.path(proj_path, "calc-tax-sole.R"))
lst_sole = calc_tax_sole(proj_path, income, expense)
lst_sole[[1]]
rm(list=ls())
# user input
income = 50000
expense = 10000 # non-salary biz expense
# set paths
proj_path = "~/Dropbox/me/tax-calculator"
source(file.path(proj_path, "calc-tax-sole.R"))
source(file.path(proj_path, "calc-tax-sole-no-401k.R"))
lst_sole = calc_tax_sole(proj_path, income, expense)
lst_sole[[1]]
lst_sole = calc_tax_sole_no_401k(proj_path, income, expense)
lst_sole[[1]]
rm(list=ls())
# user input
income = 50000
expense = 10000 # non-salary biz expense
# set paths
proj_path = "~/Dropbox/me/tax-calculator"
source(file.path(proj_path, "calc-tax-sole.R"))
source(file.path(proj_path, "calc-tax-sole-no-401k.R"))
lst_sole = calc_tax_sole(proj_path, income, expense)
lst_sole[[1]]
lst_sole[[2]]
lst_sole_no_401k = calc_tax_sole_no_401k(proj_path, income, expense)
lst_sole_no_401k[[1]]
lst_sole_no_401k[[2]]
proj_path = "~/score-loan-applicants"
data_path = file.path(proj_path, 'data')
file_path = file.path(data_path, 'cleaned-06.rda')
load(file_path)
# split dat into training (60%) and testing (40%) sets
set.seed(123294)
train = sample(1:nrow(upl), round(nrow(upl)*0.6))
dat_train = upl[train, ]
dat_test = upl[-train, ]
library(glmulti)
t0 = proc.time() # record starting time
f = as.formula(paste0("bad ~ ", paste(predictors, collapse=" + ")))
bestsub_logit = glmulti(f, data = dat_train,
level = 1, # no interaction considered
method = "h", # exhaustive approach
crit = "aic", # AIC as criteria
confsetsize = 5, # keep 5 best models
plotty = F, report = F, # no plot or interim reports
fitfunction = "glm", # glm function
family = binomial) # binomial family for logit model
cat("Run time: ")
print(proc.time() - t0) # calculating time it took to run the models
temp = as.character(bestsub_logit@formulas[[1]])[3]
main_effects = strsplit(temp, " \\+ ")[[1]][-1]
interact_terms1 = c("marital:bankruptcy",
"bankruptcy:market_value_cat")
interact_terms2 = c("credit_line_age:bankruptcy",
"credit_line_age:market_value_cat",
"log_annual_income:bankruptcy",
"log_annual_income:market_value_cat")
interactions = c(interact_terms1, interact_terms2)
base_model = paste0("bad ~ ", paste(main_effects, collapse=" + "))
# create list of models
list_of_models = lapply(seq_along(interactions), function(n) {
left = base_model
right = apply(combn(interactions, n), 2, paste, collapse = " + ")
paste(left, right, sep = " + ")
})
# convert to vector
vec_of_models = unlist(list_of_models)
vec_of_models = c(base_model, vec_of_models)
list_of_fits = lapply(vec_of_models, function(x) {
formula = as.formula(x)
fit = glm(formula, data=dat_train, family=binomial)
result_AIC = extractAIC(fit)
data.frame(predictor_cnt = result_AIC[1],
AIC = result_AIC[2], model = x, stringsAsFactors=F)
})
result = do.call(rbind, list_of_fits) # collapse to a data frame
result = result[order(result$AIC),] # sort
fbest = as.formula(result$model[1])
fbest
bestfit = glm(fbest, data=dat_train, family=binomial)
round(coef(bestfit), 3)
threshold = 0.5
prob = predict(bestfit, dat_test, type="response")
pred = ifelse(prob > threshold, 1, 0)
tbl_logit = table(pred, truth = dat_test$bad)
print(tbl_logit)
test_accuracy = sum(pred == dat_test$bad) / length(pred)
paste0(round(test_accuracy*100, 2), "%")
mk_tbl = function(pred, truth) {
# pred: a vector of the predicted class labels
# truth: a vector of the true labels
tbl = table(prediction = pred, truth = truth)
rownames = row.names(tbl)
if (length(rownames) == 1) {
if (rownames == "0")
tbl = rbind(tbl, c(0, 0))
if (rownames == "1")
tbl = rbind(c(0, 0), tbl)
row.names(tbl) = c("0", "1")
}
tbl
}
calc_accuracy = function(tbl) {
# tbl: a confusion table with predictions along the rows and
#      truth along the columns
sum(diag(tbl)) / sum(tbl)
}
calc_tpr = function(tbl) {
# tbl: a confusion table with predictions along the rows and
#      truth along the columns
TP = tbl["1", "1"]
FN = tbl["0", "1"]
TP / (TP + FN)
}
print_format = function(num) paste0(round(num*100, 2), "%")
pred = rep(0, length(dat_test$bad))
tbl_bench = mk_tbl(pred, dat_test$bad)
tbl_bench
prob = predict(bestfit, dat_test, type="response")
pred = ifelse(prob > threshold, 1, 0)
tbl_logit = mk_tbl(pred, dat_test$bad)
tbl_logit
print_format(calc_accuracy(tbl_bench))
print_format(calc_accuracy(tbl_logit))
print_format(calc_tpr(tbl_bench))
print_format(calc_tpr(tbl_logit))
calc_fpr = function(tbl) {
# tbl: a confusion table with predictions along the rows and
#      truth along the columns
FP = tbl["1", "0"]
TN = tbl["0", "0"]
FP / (FP + TN)
}
print_format(calc_fpr(tbl_bench))
print_format(calc_fpr(tbl_logit))
calc_precision = function(tbl) {
# tbl: a confusion table with predictions along the rows and
#      truth along the columns
TP = tbl["1", "1"]
FP = tbl["1", "0"]
TP / (TP + FP)
}
print_format(calc_precision(tbl_bench))
print_format(calc_precision(tbl_logit))
calc_F = function(tbl) {
# tbl: a confusion table with predictions along the rows and
#      truth along the columns
precision = calc_precision(tbl)
recall = calc_tpr(tbl)
2 / (1/precision + 1/recall)
}
print_format(calc_F(tbl_bench))
print_format(calc_F(tbl_logit))
prob = predict(bestfit, dat_test, type="response")
range(prob)
cutoffs = seq(0, 1, 0.01)
vec_tpr = vec_fpr = vec_precision = vec_F = vec_accuracy =  rep(NA, length(cutoffs))
names(vec_tpr) = names(vec_fpr) = names(vec_precision) = names(vec_F) =
names(vec_accuracy) = cutoffs
for (threshold in cutoffs) {
pred = ifelse(prob > threshold, 1, 0)
tbl = mk_tbl(pred, dat_test$bad)
vec_tpr[as.character(threshold)] = calc_tpr(tbl)
vec_fpr[as.character(threshold)] = calc_fpr(tbl)
vec_precision[as.character(threshold)] = calc_precision(tbl)
vec_F[as.character(threshold)] = calc_F(tbl)
vec_accuracy[as.character(threshold)] = calc_accuracy(tbl)
}
head(vec_tpr)
tail(vec_tpr)
range(vec_tpr)
prob = predict(bestfit, dat_test, type="response")
cutoffs = seq(0, 1, 0.01)
vec_accuracy = vec_tpr = vec_fpr = vec_precision = vec_F =
rep(NA, length(cutoffs))
names(vec_accuracy) = names(vec_tpr) = names(vec_fpr) = names(vec_precision) =
names(vec_F) = cutoffs
for (threshold in cutoffs) {
pred = ifelse(prob > threshold, 1, 0)
tbl = mk_tbl(pred, dat_test$bad)
vec_accuracy[as.character(threshold)] = calc_accuracy(tbl)
vec_tpr[as.character(threshold)] = calc_tpr(tbl)
vec_fpr[as.character(threshold)] = calc_fpr(tbl)
vec_precision[as.character(threshold)] = calc_precision(tbl)
vec_F[as.character(threshold)] = calc_F(tbl)
}
dat_roc = data.frame(fpr=vec_fpr, tpr=vec_tpr)
plt = mk_scatterplot(dat_roc)
p = plt("fpr", "tpr", xlab="False Positive Rate (1 - Specificity)",
ylab="True Positive Rate (Sensitivity/Recall)",
pt_size=1.5, pt_alpha=1)
library(ezplot)
dat_roc = data.frame(fpr=vec_fpr, tpr=vec_tpr)
plt = mk_scatterplot(dat_roc)
p = plt("fpr", "tpr", xlab="False Positive Rate (1 - Specificity)",
ylab="True Positive Rate (Sensitivity/Recall)",
pt_size=1.5, pt_alpha=1)
p = scale_axis(p, "x", use_pct=T, pct_jump=0.1)
p = scale_axis(p, "y", use_pct=T, pct_jump=0.1)
print(p)
calc_auc = function(fpr, tpr) {
# calculates the AUC
# fpr, tpr: numeric vectors
names(fpr) = names(tpr) = NULL
auc = 0
for (i in 2:length(fpr)) # adds up the areas of the trapezoids
auc = auc + 0.5 * (tpr[i] + tpr[i - 1]) * abs(fpr[i] - fpr[i - 1])
auc
}
calc_auc(vec_fpr, vec_tpr)
dat_prec_recall = data.frame(precision=vec_precision, recall=vec_tpr)
# plot Precision vs. Recall
plt = mk_scatterplot(dat_prec_recall)
p = plt("recall", "precision", xlab="Recall (Sensitivity/TPR)",
ylab="Precision", pt_size=1.5, pt_alpha=1)
p = scale_axis(p, "x", use_pct=T, pct_jump=0.1)
p = scale_axis(p, "y", use_pct=T, pct_jump=0.1)
print(p)
library(dplyr)
library(tidyr)
# gather data into data frame for plotting
dat_plt = data.frame(fpr=vec_fpr, precision=vec_precision, F_measure=vec_F,
tpr=vec_tpr, accuracy=vec_accuracy)
dat_plt = dat_plt %>% gather(type, val, -fpr)
# plot Precision, F-measure, TPR and accuracy vs. FPR
plt = mk_scatterplot(dat_plt)
p = plt("fpr", "val", fillby="type", pt_size=1.5, pt_alpha=1, ylab="",
xlab="False Positive Rate (1 - Specificity)")
p = scale_axis(p, "x", use_pct=T, pct_jump=0.1)
p = scale_axis(p, "y", use_pct=T, pct_jump=0.1)
print(p)
print_format(calc_tpr(tbl_logit))
print_format(calc_fpr(tbl_logit))
library(knitr)
opts_knit$set(out.format = "markdown")
proj_path = "~/write/score-loan-applicants-book"
manu_path = file.path(proj_path, "manuscript")
setwd(manu_path)
rmd_path = file.path(manu_path, "Rmd")
file_in = file.path(rmd_path, "03-03-performance-curves.Rmd")
knitr::knit(file_in)
file_in = file.path(rmd_path, "03-03-performance-curves.Rmd")
knitr::knit(file_in)
get_folds = function(k, dat) sample(rep(1:k, length=nrow(dat)))
# set seed
set.seed(292303)
K = 10 # number of folds
folds = get_folds(K, dat_train) # get ids for each of the K folds.
# initialization
cutoffs = seq(0, 1, 0.01)
cv_opt_cutoff = rep(NA, K)
cv_tpr = rep(NA, K)
cv_accuracy = rep(NA, K)
# run 10-fold Cross Validation
for (i in 1:K) {
# fit model using K-i folds and predict on the ith fold
subtrain = dat_train[folds!=i, ]
subtest  = dat_test[folds==i, ]
fit = glm(fbest, data=subtrain, family=binomial)
prob = predict(fit, subtest, type="response")
# find optimal threshold for fold i
target_tpr = target_accuracy = 0.8
epsilon = 0.05
opt_threshold = result_tpr = result_accuracy = c()
for (threshold in cutoffs) {
pred = ifelse(prob > threshold, 1, 0)
tbl = mk_tbl(pred, subtest$bad)
tpr = calc_tpr(tbl)
accuracy = calc_accuracy(tbl)
if (abs(tpr - target_tpr) < epsilon &&
abs(accuracy - target_accuracy) < epsilon) {
result_tpr = c(result_tpr, tpr)
result_accuracy = c(result_accuracy, accuracy)
opt_threshold = c(opt_threshold, threshold)
}
}
cv_opt_cutoff[i] = mean(opt_threshold)
cv_tpr[i] = mean(result_tpr)
cv_accuracy[i] = mean(result_accuracy)
}
print(cv_tpr)
print(cv_accuracy)
print(cv_opt_cutoff)
prob = predict(bestfit, dat_test, type="response")
pred = ifelse(prob > opt_threshold, 1, 0)
tbl_logit = table(pred, truth = dat_test$bad)
print_format(calc_fpr(tbl_logit))
opt_threshold = mean(cv_opt_cutoff)
print(opt_threshold)
prob = predict(bestfit, dat_test, type="response")
pred = ifelse(prob > opt_threshold, 1, 0)
tbl_logit = table(pred, truth = dat_test$bad)
print_format(calc_fpr(tbl_logit))
data.frame(Accuracy = print_format(calc_accuracy(tbl_logit)),
TPR = print_format(calc_tpr(tbl_logit)),
FPR = print_format(calc_fpr(tbl_logit)),
Precision = print_format(calc_precision(tbl_logit)),
F = print_format(calc_F(tbl_logit)))
print_format
1-calc_fpr(tbl_logit)
round(1-calc_fpr(tbl_logit), 2) * 100
round(1 - calc_tpr(tbl_logit), 2) * 100
1 - calc_fpr(tbl_logit)
round(1 - calc_tpr(tbl_logit), 2) * 100
1 - calc_tpr(tbl_logit)
round(1 - calc_tpr(tbl_logit), 3)
round(1 - calc_tpr(tbl_logit), 3) * 5
0.787 - 1.847*0.18
file_in = file.path(rmd_path, "03-04-cross-validation.Rmd")
knitr::knit(file_in)
file_in = file.path(rmd_path, "03-04-cross-validation.Rmd")
knitr::knit(file_in)
print_format(cv_tpr)
print_format(cv_accuracy)
file_in = file.path(rmd_path, "03-04-cross-validation.Rmd")
knitr::knit(file_in)
file_in = file.path(rmd_path, "03-04-cross-validation.Rmd")
knitr::knit(file_in)
bestfit
fbest
upl
opt_threshold
finalfit = glm(fbest, data=upl, family=binomial)
round(coef(finalfit), 3)
exp(coef(finalfit))
round(exp(coef(finalfit)), 4)
round(exp(coef(finalfit)[-1]), 4)
file_in = file.path(rmd_path, "03-05-final-model.Rmd")
knitr::knit(file_in)
fbest
str(fbest)
file_in = file.path(rmd_path, "03-05-final-model.Rmd")
knitr::knit(file_in)
file_in = file.path(rmd_path, "03-05-final-model.Rmd")
knitr::knit(file_in)
file_in = file.path(rmd_path, "03-05-final-model.Rmd")
knitr::knit(file_in)
odds_ratio = exp(coef(finalfit)[-1])
round(odds_ratio, 3)
odds_ratio[1]
1-odds_ratio[1]
print_format(1-odds_ratio[1])
?format_as_percent
ezplot
library(ezplot)
?format
?format_as_pct
format_as_pct(1-odds_ratio[1], 3)
1-odds_ratio[2]
round(odds_ratio[2] - 1)
round(odds_ratio[2] - 1, 1)
round(odds_ratio[3] - 1, 1)
round(1 - odds_ratio[3], 1)
format_as_pct(1 - odds_ratio[4], 1)
format_as_pct(1 - odds_ratio[4], 2)
format_as_pct(1 - odds_ratio[4], 3)
e
e1
exp(1)
round(exp(1),3)
round(exp(1),1)
round(exp(1),1)-1
format_as_pct(1 - odds_ratio[4], 3)
format_as_pct(1 - odds_ratio[5], 3)
format_as_pct(1 - odds_ratio[7], 3)
format_as_pct(1 - odds_ratio[8], 3)
?upl
upl
format_as_pct(1 - odds_ratio[8], 3)
format_as_pct(12*(1 - odds_ratio[8]), 3)
file_in = file.path(rmd_path, "03-05-final-model.Rmd")
knitr::knit(file_in)
166.67/2
2.48/75
2.48*2/150
